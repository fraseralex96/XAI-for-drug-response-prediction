{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-07 14:21:22.586789: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-07 14:21:22.838291: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-08-07 14:21:22.844466: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-08-07 14:21:22.844482: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-08-07 14:21:22.873657: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-08-07 14:21:39.392224: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-08-07 14:21:39.392405: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-08-07 14:21:39.392427: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import sklearn\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import scipy\n",
    "import pickle\n",
    "from importlib import reload\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from collections import namedtuple\n",
    "import keras_tuner as kt \n",
    "codebase_path = '/data/home/wpw035/Codebase'\n",
    "sys.path.insert(0, codebase_path) #add path to my codebase models\n",
    "from scipy.optimize import curve_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DRP_utils import data_preprocessing as dp_nb\n",
    "reload(dp_nb)\n",
    "from DRP_utils import model_selection as ms_nb\n",
    "reload(ms_nb)\n",
    "from DRP_utils import testing as t_nb\n",
    "reload(t_nb)\n",
    "import Data_imports as di_nb\n",
    "reload(di_nb)\n",
    "import pairs_train_test_split as tts_nb\n",
    "import Learning_curve as lc_nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/home/bt22941/ML_notebook/Nikhil_code/Data_imports.py:45: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support skipfooter; you can avoid this warning by specifying engine='python'.\n",
      "  uniprot_ids = pd.read_csv(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing prot values 0.386335609896865\n",
      "num non overlapping prot and target cls: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/home/bt22941/ML_notebook/Nikhil_code/Data_imports.py:80: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support skipfooter; you can avoid this warning by specifying engine='python'.\n",
      "  cell_names_raw = pd.read_csv(f'{gdsc_path}/downloaded_data/gdsc_cell_names.csv', skiprows=1, skipfooter=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num non overlapping cls: 930\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((38, 8457), (38, 17417), (38, 22804), (38, 38), (345, 345))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#input data\n",
    "prot, rna, phospho_ls, one_hot_cls, one_hot_drugs, ic50_df1 = di_nb.read_input_data()\n",
    "_all_cls = prot.index\n",
    "_all_drugs = ic50_df1.columns\n",
    "assert prot.shape[0] == rna.shape[0] == phospho_ls.shape[0]\n",
    "assert phospho_ls.shape[0]  == one_hot_cls.shape[0]\n",
    "prot.shape, rna.shape, phospho_ls.shape, one_hot_cls.shape, one_hot_drugs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Featrue selection (FS) and data createing for each drug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11583, 908), (11583, 345), 11583)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read in landmark genes for fs and find landmarks that overlap with rna data\n",
    "landmark_genes = pd.read_csv(\n",
    "    f'../data/Landmark_genes_LINCS.txt',sep='\\t')\n",
    "landmark_genes.index = landmark_genes['Symbol']\n",
    "\n",
    "overlapping_landmarks, _ = dp_nb.keep_overlapping(\n",
    "    pd.DataFrame(landmark_genes['Symbol']), rna.T)\n",
    "\n",
    "overlapping_landmarks = overlapping_landmarks['Symbol'].values\n",
    "\n",
    "#create input data for each drug\n",
    "x_all, x_drug, y_list = dp_nb.create_all_drugs(\n",
    "    rna[overlapping_landmarks], one_hot_drugs, ic50_df1, _all_cls)\n",
    "\n",
    "x_all = x_all.astype(np.float32)\n",
    "x_drug = x_drug.astype(np.float16)\n",
    "\n",
    "#fmt index to include drug cell line paris\n",
    "cls_drugs_index = x_all.index + '::' + x_drug.index\n",
    "x_all.index = cls_drugs_index\n",
    "x_drug.index = cls_drugs_index\n",
    "y_list.index = cls_drugs_index\n",
    "\n",
    "x_all.shape, x_drug.shape, len(y_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11583, 721)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#use the same landmark genes for fs with prot data\n",
    "\n",
    "landmark_genes = pd.read_csv(\n",
    "    f'../data/Landmark_genes_LINCS.txt',sep='\\t')\n",
    "landmark_genes.index = landmark_genes['Symbol']\n",
    "\n",
    "#find overlapping landmark genes and prot features\n",
    "overlapping_landmarks, _ = dp_nb.keep_overlapping(\n",
    "    pd.DataFrame(landmark_genes['Symbol']), prot.T)\n",
    "\n",
    "overlapping_landmarks = overlapping_landmarks['Symbol'].values\n",
    "\n",
    "#create prot data for all drugs\n",
    "x_all_prot, x_drug, y_list = dp_nb.create_all_drugs(\n",
    "    prot[overlapping_landmarks], one_hot_drugs, ic50_df1, _all_cls)\n",
    "\n",
    "#fmt index to include drug cell line paris\n",
    "cls_drugs_index = x_all_prot.index + '::' + x_drug.index \n",
    "x_all_prot.index = cls_drugs_index\n",
    "y_list.index = cls_drugs_index\n",
    "x_drug.index = cls_drugs_index\n",
    "\n",
    "x_all_prot = x_all_prot.astype(np.float32)\n",
    "x_all_prot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def landmark_X_maker(X, landmarkGenes):\n",
    "    #reindex X with only the landmark genes\n",
    "    L1000 = []\n",
    "    for i in X.columns:\n",
    "        if i.split('(')[0] in landmarkGenes:\n",
    "            L1000.append(i)\n",
    "    X_L1000 = X.reindex(L1000,axis=\"columns\")  \n",
    "    return X_L1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11583, 1801)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#use the same landmark genes, that were used for fs for rna datan\n",
    "#for fs with phospho data\n",
    "\n",
    "X_L1000 = landmark_X_maker(phospho_ls, overlapping_landmarks)\n",
    "\n",
    "#create prot data for all drugs\n",
    "x_all_phos, x_drug, y_list = dp_nb.create_all_drugs(\n",
    "    X_L1000, one_hot_drugs, ic50_df1, _all_cls)\n",
    "\n",
    "#fmt index to include drug cell line paris\n",
    "cls_drugs_index = x_all_phos.index + '::' + x_drug.index \n",
    "x_all_phos.index = cls_drugs_index\n",
    "y_list.index = cls_drugs_index\n",
    "x_drug.index = cls_drugs_index\n",
    "\n",
    "x_all_phos = x_all_phos.astype(np.float32)\n",
    "x_all_phos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11583, 38)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#one hot data creation for all drugs\n",
    "x_hot, x_drug_hot, y_hot = dp_nb.create_all_drugs(\n",
    "    one_hot_cls, one_hot_drugs, ic50_df1, _all_cls)\n",
    "\n",
    "cls_drugs_index_hot = x_hot.index + '::' + x_drug_hot.index \n",
    "\n",
    "x_hot.index = cls_drugs_index_hot\n",
    "x_hot.columns = np.arange(len(x_drug.columns), len(x_drug.columns) + len(x_hot.columns))\n",
    "x_hot.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "_input_shape=None\n",
    "def build_cnn_kt(hp):\n",
    "    if _input_shape == None:\n",
    "        raise Exception('add input shape dim')\n",
    "    phos_input = layers.Input(shape=(_input_shape, 1))\n",
    "    x = layers.Conv1D(\n",
    "        filters=hp.Int('filts', 8, 32, 8), kernel_size=16, \n",
    "        activation='relu')(phos_input)\n",
    "    x = layers.MaxPooling1D(pool_size=2)(x)\n",
    "    x = layers.Conv1D(\n",
    "        filters=hp.Int('filts',8, 32, 8), kernel_size=8, activation='relu')(x)\n",
    "    x = layers.MaxPooling1D(pool_size=2)(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(hp.Int('units', 32, 258, 32), activation='relu')(x)\n",
    "    x = layers.Dense(hp.Int('units', 32, 258, 32), activation='relu')(x)\n",
    "    drug_input = layers.Input(shape = (xdrug_train.shape[1]))\n",
    "    concatenated = layers.concatenate([x, drug_input])\n",
    "    hidd = layers.Dense(hp.Int('units_hid', 32, 258, 32), activation='relu')(concatenated)\n",
    "    hidd = layers.Dense(hp.Int('units_hid', 32, 258, 32), activation='relu')(hidd)\n",
    "    output_tensor = layers.Dense(1)(hidd)\n",
    "    model = tf.keras.Model([phos_input,drug_input], output_tensor)\n",
    "    opt = tf.keras.optimizers.RMSprop(learning_rate=hp.Choice('lr', [1e-4, 1e-3]))\n",
    "    model.compile(optimizer=opt, loss=tf.keras.metrics.mean_squared_error, metrics=['mae'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   2,    4,   11,   26,   64,   70,   77,   85,   93,  103,  113,\n",
       "        125,  137,  151,  166,  183,  201,  221,  244,  268,  295,  325,\n",
       "        358,  394,  433,  477,  525,  577,  635,  699,  769,  847,  932,\n",
       "       1025, 1128, 1242, 1366, 1503, 1654, 1821, 2003, 2205, 2426, 2669,\n",
       "       2937, 3232, 3557, 3914, 4307, 4740, 5215, 5739, 6315, 6949])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_train_size  = 0.6 #train size relative to total data set size\n",
    "lg_space = np.logspace(1, np.log2(64), base=2.0, num=5).astype(int)\n",
    "lg2 = np.logspace(np.log2(64), np.log2(len(x_all) * _train_size),  base=2.0, num=50).astype(int)\n",
    "lg_space = np.concatenate((lg_space, lg2))\n",
    "lg_space = np.unique(lg_space)\n",
    "lg_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 6 Complete [00h 00m 06s]\n",
      "val_loss: 4.894872665405273\n",
      "\n",
      "Best val_loss So Far: 4.737700939178467\n",
      "Total elapsed time: 00h 00m 53s\n",
      "\n",
      "Search: Running Trial #7\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "8                 |24                |filts\n",
      "64                |96                |units\n",
      "64                |160               |units_hid\n",
      "0.0001            |0.001             |lr\n",
      "\n",
      "Epoch 1/100\n",
      "4/4 [==============================] - 1s 121ms/step - loss: 9.3200 - mae: 2.6338 - val_loss: 9.6109 - val_mae: 2.6646\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 9.2677 - mae: 2.6249 - val_loss: 9.5665 - val_mae: 2.6574\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 9.2298 - mae: 2.6188 - val_loss: 9.5288 - val_mae: 2.6512\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 9.1960 - mae: 2.6131 - val_loss: 9.4941 - val_mae: 2.6455\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 9.1648 - mae: 2.6078 - val_loss: 9.4609 - val_mae: 2.6400\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 9.1349 - mae: 2.6026 - val_loss: 9.4277 - val_mae: 2.6346\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 9.1049 - mae: 2.5977 - val_loss: 9.3941 - val_mae: 2.6290\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 9.0744 - mae: 2.5924 - val_loss: 9.3592 - val_mae: 2.6232\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 9.0431 - mae: 2.5871 - val_loss: 9.3235 - val_mae: 2.6173\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 9.0113 - mae: 2.5815 - val_loss: 9.2870 - val_mae: 2.6112\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 8.9788 - mae: 2.5759 - val_loss: 9.2498 - val_mae: 2.6049\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 8.9459 - mae: 2.5702 - val_loss: 9.2115 - val_mae: 2.5985\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 8.9116 - mae: 2.5642 - val_loss: 9.1712 - val_mae: 2.5917\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 8.8764 - mae: 2.5582 - val_loss: 9.1308 - val_mae: 2.5848\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 8.8409 - mae: 2.5516 - val_loss: 9.0882 - val_mae: 2.5776\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 8.8041 - mae: 2.5452 - val_loss: 9.0443 - val_mae: 2.5702\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 8.7666 - mae: 2.5383 - val_loss: 8.9973 - val_mae: 2.5622\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 8.7264 - mae: 2.5312 - val_loss: 8.9497 - val_mae: 2.5540\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 8.6865 - mae: 2.5235 - val_loss: 8.9025 - val_mae: 2.5459\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 8.6455 - mae: 2.5162 - val_loss: 8.8510 - val_mae: 2.5369\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 8.6034 - mae: 2.5083 - val_loss: 8.7989 - val_mae: 2.5278\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 8.5598 - mae: 2.5001 - val_loss: 8.7432 - val_mae: 2.5180\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 8.5137 - mae: 2.4918 - val_loss: 8.6828 - val_mae: 2.5072\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 8.4659 - mae: 2.4823 - val_loss: 8.6235 - val_mae: 2.4966\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 8.4178 - mae: 2.4734 - val_loss: 8.5603 - val_mae: 2.4852\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 8.3682 - mae: 2.4633 - val_loss: 8.4978 - val_mae: 2.4738\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 8.3170 - mae: 2.4541 - val_loss: 8.4292 - val_mae: 2.4612\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 8.2641 - mae: 2.4443 - val_loss: 8.3585 - val_mae: 2.4481\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 8.2109 - mae: 2.4340 - val_loss: 8.2911 - val_mae: 2.4355\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 8.1600 - mae: 2.4225 - val_loss: 8.2236 - val_mae: 2.4227\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 8.1060 - mae: 2.4121 - val_loss: 8.1480 - val_mae: 2.4081\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 8.0489 - mae: 2.4002 - val_loss: 8.0737 - val_mae: 2.3935\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 7.9920 - mae: 2.3881 - val_loss: 7.9928 - val_mae: 2.3774\n",
      "Epoch 34/100\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 7.9326 - mae: 2.3756 - val_loss: 7.9150 - val_mae: 2.3617\n",
      "Epoch 35/100\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 7.8767 - mae: 2.3626 - val_loss: 7.8409 - val_mae: 2.3466\n",
      "Epoch 36/100\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 7.8204 - mae: 2.3511 - val_loss: 7.7612 - val_mae: 2.3300\n",
      "Epoch 37/100\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 7.7629 - mae: 2.3379 - val_loss: 7.6796 - val_mae: 2.3127\n",
      "Epoch 38/100\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 7.7072 - mae: 2.3245 - val_loss: 7.6036 - val_mae: 2.2962\n",
      "Epoch 39/100\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 7.6501 - mae: 2.3111 - val_loss: 7.5265 - val_mae: 2.2790\n",
      "Epoch 40/100\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 7.5977 - mae: 2.2976 - val_loss: 7.4523 - val_mae: 2.2622\n",
      "Epoch 41/100\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 7.5459 - mae: 2.2853 - val_loss: 7.3784 - val_mae: 2.2449\n",
      "Epoch 42/100\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 7.4945 - mae: 2.2710 - val_loss: 7.3134 - val_mae: 2.2294\n",
      "Epoch 43/100\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 7.4568 - mae: 2.2593 - val_loss: 7.2631 - val_mae: 2.2173\n",
      "Epoch 44/100\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 7.4183 - mae: 2.2489 - val_loss: 7.2171 - val_mae: 2.2061\n",
      "Epoch 45/100\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 7.3791 - mae: 2.2400 - val_loss: 7.1597 - val_mae: 2.1917\n",
      "Epoch 46/100\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 7.3422 - mae: 2.2278 - val_loss: 7.1120 - val_mae: 2.1796\n",
      "Epoch 47/100\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 7.3072 - mae: 2.2163 - val_loss: 7.0672 - val_mae: 2.1680\n",
      "Epoch 48/100\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 7.2746 - mae: 2.2060 - val_loss: 7.0228 - val_mae: 2.1561\n",
      "Epoch 49/100\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 7.2424 - mae: 2.1965 - val_loss: 6.9766 - val_mae: 2.1433\n",
      "Epoch 50/100\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 7.2098 - mae: 2.1855 - val_loss: 6.9376 - val_mae: 2.1321\n",
      "Epoch 51/100\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 7.1823 - mae: 2.1751 - val_loss: 6.9006 - val_mae: 2.1211\n",
      "Epoch 52/100\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 7.1589 - mae: 2.1674 - val_loss: 6.8666 - val_mae: 2.1107\n",
      "Epoch 53/100\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 7.1316 - mae: 2.1565 - val_loss: 6.8419 - val_mae: 2.1031\n",
      "Epoch 54/100\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 7.1096 - mae: 2.1497 - val_loss: 6.8169 - val_mae: 2.0952\n",
      "Epoch 55/100\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 7.0911 - mae: 2.1440 - val_loss: 6.7950 - val_mae: 2.0881\n",
      "Epoch 56/100\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 7.0659 - mae: 2.1360 - val_loss: 6.7774 - val_mae: 2.0826\n",
      "Epoch 57/100\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 7.0498 - mae: 2.1299 - val_loss: 6.7628 - val_mae: 2.0782\n",
      "Epoch 58/100\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 7.0346 - mae: 2.1270 - val_loss: 6.7471 - val_mae: 2.0732\n",
      "Epoch 59/100\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 7.0115 - mae: 2.1199 - val_loss: 6.7395 - val_mae: 2.0716\n",
      "Epoch 60/100\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 7.0134 - mae: 2.1226 - val_loss: 6.7282 - val_mae: 2.0681\n",
      "Epoch 61/100\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 6.9797 - mae: 2.1145 - val_loss: 6.7159 - val_mae: 2.0642\n",
      "Epoch 62/100\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 6.9640 - mae: 2.1085 - val_loss: 6.7088 - val_mae: 2.0627\n",
      "Epoch 63/100\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 6.9506 - mae: 2.1061 - val_loss: 6.6999 - val_mae: 2.0604\n",
      "Epoch 64/100\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 6.9317 - mae: 2.1025 - val_loss: 6.6903 - val_mae: 2.0578\n",
      "Epoch 65/100\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 6.9153 - mae: 2.0975 - val_loss: 6.6832 - val_mae: 2.0565\n",
      "Epoch 66/100\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 6.8994 - mae: 2.0965 - val_loss: 6.6721 - val_mae: 2.0532\n",
      "Epoch 67/100\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 6.8868 - mae: 2.0909 - val_loss: 6.6627 - val_mae: 2.0506\n",
      "Epoch 68/100\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 6.8698 - mae: 2.0893 - val_loss: 6.6524 - val_mae: 2.0475\n",
      "Epoch 69/100\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 6.8538 - mae: 2.0831 - val_loss: 6.6493 - val_mae: 2.0477\n",
      "Epoch 70/100\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 6.8323 - mae: 2.0805 - val_loss: 6.6403 - val_mae: 2.0453\n",
      "Epoch 71/100\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 6.8212 - mae: 2.0748 - val_loss: 6.6348 - val_mae: 2.0444\n",
      "Epoch 72/100\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 6.8001 - mae: 2.0729 - val_loss: 6.6263 - val_mae: 2.0423\n",
      "Epoch 73/100\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 7.2291 - mae: 2.1976"
     ]
    }
   ],
   "source": [
    "#One hot\n",
    "#finds a test train split then finds the learning curve\n",
    "#for that split. Repeats for mutiple (N) test train splits \n",
    "N = 30\n",
    "t1 = time.time()\n",
    "for run in range(N):\n",
    "    print(f'run {run} of {N}')\n",
    "    #test train split\n",
    "    rand_seed = 42 + run\n",
    "    pairs_with_truth_vals =  y_list.index\n",
    "    train_pairs, test_pairs, val_pairs = tts_nb.split(\n",
    "        rand_seed, _all_cls, _all_drugs, pairs_with_truth_vals,\n",
    "        train_size=_train_size)\n",
    "\n",
    "    #rna test train selection\n",
    "    x_train_rna, x_test_rna = x_all.loc[train_pairs], x_all.loc[test_pairs]\n",
    "    x_val_rna = x_all.loc[val_pairs]\n",
    "    y_train, y_test = y_list[train_pairs], y_list[test_pairs]\n",
    "    y_val = y_list[val_pairs]\n",
    "    xdrug_train, xdrug_test = x_drug.loc[train_pairs], x_drug.loc[test_pairs]\n",
    "    xdrug_val = x_drug.loc[val_pairs]\n",
    "\n",
    "    #prot test train selection\n",
    "    x_train_prot, x_test_prot = x_all_prot.loc[train_pairs], x_all_prot.loc[test_pairs]\n",
    "    x_val_prot = x_all_prot.loc[val_pairs]\n",
    "\n",
    "    #one hot test train seleciton\n",
    "    x_train_hot, x_test_hot = x_hot.loc[train_pairs], x_hot.loc[test_pairs]\n",
    "    x_val_hot = x_hot.loc[val_pairs]\n",
    "    \n",
    "    #consistencey checks\n",
    "    assert (x_train_hot.index == x_train_rna.index).all()\n",
    "    assert (x_test_hot.index == x_test_rna.index).all()\n",
    "    assert (x_val_hot.index == x_val_rna.index).all()\n",
    "\n",
    "    assert (x_train_prot.index == x_train_rna.index).all()\n",
    "    assert (x_test_prot.index == x_test_rna.index).all()\n",
    "    assert (x_val_prot.index == x_val_rna.index).all()\n",
    "\n",
    "    assert (y_train.index == x_train_rna.index).all()\n",
    "    assert (y_test.index == x_test_rna.index).all()\n",
    "    assert (xdrug_test.index == x_test_rna.index).all()\n",
    "\n",
    "    #inconsistencey checks\n",
    "    assert x_train_rna.shape[1] != x_train_prot.shape[1]\n",
    "    assert x_test_rna.shape[1] != x_test_prot.shape[1]\n",
    "    assert x_val_rna.shape[1] != x_val_prot.shape[1]\n",
    "\n",
    "    assert x_train_rna.shape[1] != x_train_hot.shape[1]\n",
    "    assert x_test_rna.shape[1] != x_test_hot.shape[1]\n",
    "    assert x_val_rna.shape[1] != x_val_hot.shape[1]\n",
    "\n",
    "    assert x_train_prot.shape[1] != x_train_hot.shape[1]\n",
    "    assert x_test_prot.shape[1] != x_test_hot.shape[1]\n",
    "\n",
    "    del x_train_rna, x_val_rna, x_test_rna\n",
    "    del x_train_prot, x_val_prot, x_test_prot\n",
    "    \n",
    "    data_type = 'One-hot'\n",
    "    #run the learning curve\n",
    "    _input_shape = x_train_hot.shape[1]\n",
    "    mse_r2, bms, bhps = lc_nb.run_lc_ucl(\n",
    "        build_cnn_kt,\n",
    "        [x_train_hot, xdrug_train], \n",
    "        y_train, \n",
    "        [x_val_hot, xdrug_val], \n",
    "        y_val, \n",
    "        [x_test_hot, xdrug_test],\n",
    "        y_test, \n",
    "        lg_space, \n",
    "        num_trails=15,\n",
    "        epochs=100,\n",
    "        direc='UCL-del2')\n",
    "    \n",
    "    #save data\n",
    "    mse_r2.to_csv(f'LC-metric-results/{data_type}/run{run}')\n",
    "    \n",
    "    bhps_df = pd.DataFrame([bhp.values for bhp in bhps])\n",
    "    bhps_df.to_csv(f'Optimal-hyperparameters/{data_type}/run{run}df')\n",
    "    with open(f'Optimal-hyperparameters/{data_type}/run{run}.pkl', 'wb') as f:\n",
    "        pickle.dump(bhps, f)\n",
    "        \n",
    "    model_path = f'optimal-models{data_type}/run{run}/model_train_size_'\n",
    "    for train_size, model in zip(lg_space, bms):\n",
    "        model.save(model_path + str(train_size)) \n",
    "        \n",
    "    np.savetxt(f'train_test_inds/{data_type}/train_inds{run}', y_train.index, fmt='%s')\n",
    "    np.savetxt(f'train_test_inds/{data_type}/test_inds{run}', y_test.index, fmt='%s')\n",
    "    np.savetxt(f'train_test_inds/{data_type}/val_inds{run}', y_val.index, fmt='%s')\n",
    "    \n",
    "delt = time.time() - t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
